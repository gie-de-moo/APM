layout = c(4,1),
auto.key = list(columns = 3))
# overlayed density plots
transparentTheme(trans = .9)
featurePlot(x = iris[,1:4],
y = iris$Species,
plot = 'density',
# pass in options to xyplot() to
# make it prettier
scales = list(x = list(relation='free'),
y = list(relation='free')),
adjust = 1.5,
pch = '|',
layout = c(4,1),
auto.key = list(columns = 3))
featurePlot(x = iris[, 1:4],
y = iris$Species,
plot = 'box',
## pass in options to bwplot()
scales = list(y = list(relation='free'),
x = list(rot = 90)),
layout = c(4,1),
auto.key = list(columns = 2))
featurePlot(x = iris[, 1:4],
y = iris$Species,
plot = 'box')
featurePlot(x = iris[, 1:4],
y = iris$Species,
plot = 'box',
## pass in options to bwplot()
scales = list(y = list(relation='free'),
x = list(rot = 90)),
layout = c(4,1),
auto.key = list(columns = 2))
library(mlbench)
data(BostonHousing)
str(BostonHousing)
regVar = c('age','lstat','tax')
str(BostonHousing[,regVar])
theme1 = trellis.par.get()
theme1$plot.symbol$col = rgb(.2,.2,.2,.4)
names(theme1$plot.symbol)
theme1$plot.symbol$lwd = 2
theme1 = trellis.par.get()
theme1$plot.symbol$col = rgb(.2,.2,.2,.4)
theme1$plot.symbol$lwd = 2
theme1$plot.line$col = rgb(1,0,0,.7)
theme1$plot.line$lwd = 2
trellis.par.set(theme1)
theme1 = trellis.par.get()
theme1$plot.symbol$col = rgb(.2,.2,.2,.4)
theme1$plot.symbol$lwd = 2
theme1$plot.line$col = rgb(1,0,0,.7)
theme1$plot.line$lwd = 2
trellis.par.set(theme1)
featurePlot(x = BostonHousing[, regVar],
y = BostonHousing$medv,
plot = 'scatter',
layout = c(3,1))
featurePlot(x = BostonHousing[, regVar],
y = BostonHousing$medv,
plot = 'scatter',
# add smoother
type = c('p', 'smooth'),
span = 0.5,
layout = c(3,1))
library(earth)
data(etitanic)
head(etitanic)
head(model.matrix(survived ~., data = etitanic))
?model.matrix
dummies = dummyVars(survived ~ ., data = etitanic)
head(dummies)
str(etitanic)
head(predict(dummies), newdata = etitanic)
head(predict(dummies, newdata = etitanic))
ddta(mdrr)
install.packages('QSARdata')
?quote
install_load <- function(x) {
install.packages(x)
library(x)
}
install_load('QSARdata')
library(as.name('QSARdata'))
library(quote('QSARdata'))
library(a'QSARdata')
library('QSARdata')
install_load('SMCRM')
library('dplyr')
x = 'dplyr'
library(x)
library(as.character(x))
?library
install_load <- function(x) {
install.packages(x)
library(x, character.only = T)
}
library(smcrm)
library(SMCRM)
ddta(mdrr)
data(mdrr)
data.frame(table(mdrrDescr$nR11))
str(mdrrDescr)
table(mdrrDescr$nR11)
data.frame(table(mdrrDescr$nR11))
nzv = nearZeroVar(mdrrDescr, saveMetrics = T)
names(nzv)
class(nzv)
head(nzv)
nzv[nzv$nzv,]{1:10}
nzv[nzv$nzv,][1:10]
nzv[nzv$nzv,][1:10]
nzv[nzv$nzv,][1:10]
head(nzv)
nzv[nzv$nzv,][1:10]
nzv[nzv$nzv,]
nzv[nzv$nzv,][1:10,]
dim(mdrrDescr)
nzv = nearZeroVar(mdrrDescr)
nzv
filteredDescr = mdrrDescr[,-nzv]
dim(filteredDescr)
descrCor = cor(filteredDescr)
descrCor
highCorr = sum(abs(descrCor[upper.tri(descrCor)])>0.999)
highCorr
dim(filteredDescr)
65 / (297*296)
percHighCor = highCorr/(ncol(filteredDescr) ^ 2 - ncol(filteredDescr))
percHighCor
summarise(descrCor[upper.tri(descrCor)])
summary(descrCor[upper.tri(descrCor)])
highlyCorDescr = findCorrelation(descrCor, cutoff = 0.75)
filteredDescr = filteredDescr[, -highlyCorDescr]
highlyCorDescr
length(highlyCorDescr)
unique(highlyCorDescr)
length(unique(highlyCorDescr))
dim(filteredDescr)
descrCor2 = cor(filteredDescr)
detach('package::dplyr')
detach('package:dplyr')
summary(descrCor2[upper.tri(descrCor2)])
apropos('find')
help(topic = 'find', package = 'caret')
help.search(pattern =  'find', package = 'caret')
ltfrDesign = matrix(0, nrow=6, ncol=6)
ltfrDesign[, 1] <- c(1, 1, 1, 1, 1, 1)
ltfrDesign[, 2] <- c(1, 1, 1, 0, 0, 0)
ltfrDesign[, 3] <- c(0, 0, 0, 1, 1, 1)
ltfrDesign[, 4] <- c(1, 0, 0, 1, 0, 0)
ltfrDesign[, 5] <- c(0, 1, 0, 0, 1, 0)
ltfrDesign[, 6] <- c(0, 0, 1, 0, 0, 1)
ltfrDesign
rowSums(ltfrDesign)
colSums(ltfrDesign)
comboInfo = findLinearCombos(ltfrDesign)
comboInfo
ltfrDesign[,-comboInfo$remove]
set.seed(96)
inTrain = sample(seq(along=mdrrClass), length(mdrrClass)/2)
head(mdrrClass)
training = filteredDescr[inTrain,]
test = filteredDescr[-inTrain,]
trainMDRR = mdrrClass[inTrain]
testMDRR = mdrrClass[-inTrain,]
preProcValues = preProcess(training, method = c('center','scale'))
testMDRR = mdrrClass[-inTrain]
class(preProcValues)
trainTransformed = predict(preProcValues, training)
testTransformed = preProcValues(preProcValues, test)
testTransformed = predict(preProcValues, test)
args(preProcess)
?preProcess
transparentTheme(trans = .4)
plotSubset = data.frame(scale(mdrrDescr[,c('nC','X4v')]))
xyplot(nc ~ X4v,
data = plotSubset,
groups = mdrrClass,
auto.key = list(columns = 2))
xyplot(nC ~ X4v,
data = plotSubset,
groups = mdrrClass,
auto.key = list(columns = 2))
library(doMC)
apropos('core')
apropos('core', ignore.case = T)
apropos('make', ignore.case = T)
find('cluster')
makeCluster(4)
help(package = 'doMC')
registerDoMC(4)
transformed = spatialSign(plotSubset)
transformed = as.data.frame(transformed)
head(transformed)
head(plotSubset)
find('spatialSign')
xyplot(nC ~ X4v,
data = transformed,
groups = mdrrClass,
auto.key = list(columns = 2))
preProcValues2 = preProcess(training, method = 'BoxCox')
trainBC = predict(preProcValues2, training)
testBC = predict(preProcValues2, test)
preProcValues2
dim(trainBC)
dim(training)
head(training)
training[1:5,1:3]
trainBC[1:5,1:3]
trainTransformed[1:5,1:3]
trainBC[1:5,1:3]
centrorids = classDist(trainBC, trainMDRR)
?classDist
distances = predict(centrorids, testBC)
head(centrorids)
names(centroids)
names(centrorids)
centrorids$values[1:6]
table(trainMDRR)
names(centrorids$values)
names(centrorids$classes)
class(centrorids$classes)
class(centrorids$values)
centrorids$values[[1]]
names(centrorids$values[[1]])
names(centrorids$values[[1]]$mean)
names(centrorids$values[[1]]$A)
centrorids$values[[1]]$A[1:5]
centrorids$values[[1]]$means[1:5]
?classDist
distances = predict(centrorids, testBC)
distances = as.data.frame(distances)
head(distances)
xyplot(dist.Active ~ dist.Inactive,
data = distances,
groups = testMDRR,
auto.key = list(columns = 2))
library(doMC)
registerDoMC(4)
library(caret)
library(AppliedPredictiveModeling)
set.seed(3456)
set.seed(3456)
trainIndex = createDataPartition(iris$Species, p=.8,
list = FALSE,
times = 1)
head(trainIndex)
irisTrain = iris[trainIndex,]
irisTest = irise[-trainIndex,]
irisTrain = iris[trainIndex,]
irisTest = iris[-trainIndex,]
trainIndex3 = createDataPartition(iris$Species, p=.8,
list = FALSE,
times = 3)
head(trainIndex3)
tail(trainIndex3)
rm(trainIndex3)
library(mlbench)
data(BostonHousing)
testing = scale(BostonHousing[,c('age','nox')])
set.seed(11)
startSet = sample(1:dim(testing)[1],5)
samplePool = testing[-startSet,]
start = testing[startSet,]
newSamp = maxDissim(start, samplePool, n = 20)
head(newSamp)
nrow(newSamp)
length(newSamp)
?minDiss
example(sumDiss)
?do.call
minDiss
sapply(c(minDiss, sumDiss), function(obj) maxDissim(start, samplePool,
n = 20, obj = obj))
newSamp = sapply(c(minDiss, sumDiss), function(obj) maxDissim(start, samplePool,
n = 20, obj = obj))
?duplicated
?intersect
setdiff(newSamp[,1], newSamp[,2])
length(setdiff(newSamp[,1], newSamp[,2]))
resamps = resamples(list(GBM = gbmFit3,
SVM = svmFit)
summary(resamps)
resamps = resamples(list(GBM = gbmFit3,
SVM = svmFit))
summary(resamps)
library(caret)
library(doMC)
registerDoMC(cores=4)
resamps = resamples(list(GBM = gbmFit3,
SVM = svmFit))
summary(resamps)
gbmFit3 = train(Class ~., data=training,
method = 'gbm',
trControl = fitControl,
verbose = F,
tuneGrid = gbmGrid,
metric = 'ROC')
### Model Training and Tuning
library(doMC)
registerDoMC(cores=4)
## an example
library(caret)
library(mlbench)
data(Sonar)
str(Sonar[,1:10])
set.seed(998)
inTraining = createDataPartition(Sonar$Class, p = 0.75, list = F)
training = Sonar[inTraining,]
testing = Sonar[-inTraining,]
## basic parameter tuning
fitControl = trainControl(method = 'repeatedcv',
number = 10,
repeats = 10)
set.seed(825)
gbmFit1 = train(Class ~ ., data = training,
method = 'gbm',
trControl = fitControl,
verbose = F)
gbmFit1
## customizing tuning process
# alternate tuning grids
gbmGrid = expand.grid(interaction.depth = c(1,5,9),
n.trees = (1:30)*50,
shrinkage = 0.1)
nrow(gbmGrid)
set.seed(825)
gbmFit2 = train(Class~., data = training,
method = 'gbm',
trControl = fitControl,
verbose = F,
tuneGrid = gbmGrid)
# plotting the resampling profile
trellis.par.set(caretTheme())
# line plot of accuracy with each tunecombo
plot(gbmFit2)
# line plot of kappa with each tunecombo
plot(gbmFit2, metric='Kappa')
# heatmap of kappy with each tunecombo
plot(gbmFit2, metric='Kappa', plotType='level',
scales=list(x=list(rot=90)))
# using ggplt
ggplot(gbmFit2)
# can used update.train() to refit the final model
?update.train
# alternate performance metrics
fitControl = trainControl(method = 'repeatedcv',
number = 10,
repeats = 10,
classProbs = T,
summaryFunction = twoClassSummary)
set.seed(825)
gbmFit3 = train(Class ~., data=training,
method = 'gbm',
trControl = fitControl,
verbose = F,
tuneGrid = gbmGrid,
metric = 'ROC')
# since in gbmFit3 performance across tunegrid is pretty close
# find simpler model as final model
whichTwoPct = tolerance(gbmFit3$results, metric='ROC',
tol = 2, maximize = T)
cat('best model within 2 pct of best:\n')
gbmFit3$results[whichTwoPct, 1:6]
## extracting predictions and class probs
predict(gbmFit23, newdata=head(testing))
predict(gbmFit3, newdata =head(testing), type = 'prob')
## exploreing and comparing resampling distribution
#1 within model
#2 between models
set.seed(825)
svmFit = train(Class~., data=training,
method = 'svmRadial',
trControl = fitControl,
preProc = c('center','scale'),
tuneLength = 8,
metric = 'ROC')
resamps = resamples(list(GBM = gbmFit3,
SVM = svmFit))
summary(resamps)
difValues = diff(resamps)
difValues
summary(difValues)
names(resamps)
names(difValues)
gbmImp = varImp(gbmFit3, scale=F)
library(caret)
gbmImp = varImp(gbmFit3, scale=F)
?varImp
gbmImp
head(training)
RocImp = filterVarImp(x = training[,-ncol(training)],
y = training$Class)
head(RocImp)
?filterVarImp
?varImp
ls(pos = 'package:randomForest')
library(randomForest)
ls(pos = 'package:randomForest')
?varImpPlot
RocImp2 = varImp(svmFit, scale=F)
head(RocImp2)
gbmImp
head(RocImp)
RocImp2
plot(gbmImp, top=20)
library(doMC)
registerDoMC(cores=4)
library(caret)
library(mlbench)
library(Hmisc)
library(randomForest)
# simulate data sets
n <- 100
p <- 40
sigma <- 1
set.seed(1)
sim <- mlbench.friedman1(n, sd = sigma)
colnames(sim$x) <- c(paste("real", 1:5, sep = ""),
paste("bogus", 1:5, sep = ""))
bogus <- matrix(rnorm(n * p), nrow = n)
colnames(bogus) <- paste("bogus", 5+(1:ncol(bogus)), sep = "")
x <- cbind(sim$x, bogus)
y <- sim$
y
y
x
dim(x)
dim(y)
length(y)
normalization = preProcess(x)
x = predict(normalization, x)
x = as.data.frame(x)
subsets = c(1:5, 10, 15, 20, 25)
set.seed(10)
# rfe with resampling
set.seed(10)
ctrl = rfeControl(functions = lmFuncs,
method = 'repeatedcv',
repeats = 5,
verbose = F)
lmProfile = rfe(x, y,
sizes = subsets,
rfeControl = ctrl)
lmProfile
names(lmProfile)
predictors(lmProfile)
predictors(lmProfile)
predictors(lmProfile)
lmProfile$fit
trellis.par.set(caretTheme())
plot(lmProfile, type = c("g", "o"))
densityplot(lmProfile)
length(subsets)
densityplot(lmProfile, layout = c(3,3))
densityplot(resamples(lmProfile), layout = c(3,3))
rfRFE = list(summary - defaultSummary,
fit = function(x, y, first, last, ...){
library(randomForest)
randomForest(x, y, importance = first, ...)
},
pred = function(object, x) predict(object, x),
rank = function(object, x, y){
vimp = varImp(object)
vimp = vimp[order(vimp$Overall, decreasing = T), drop = F]
vimp$var = rownames(vimp)
vimp
},
selectSize = pickSizeBest,
selectVar = pickVars)
rfRFE = list(summary = defaultSummary,
fit = function(x, y, first, last, ...){
library(randomForest)
randomForest(x, y, importance = first, ...)
},
pred = function(object, x) predict(object, x),
rank = function(object, x, y){
vimp = varImp(object)
vimp = vimp[order(vimp$Overall, decreasing = T), drop = F]
vimp$var = rownames(vimp)
vimp
},
selectSize = pickSizeBest,
selectVar = pickVars)
example <- data.frame(RMSE = c(3.215, 2.819, 2.414, 2.144,
2.014, 1.997, 2.025, 1.987,
1.971, 2.055, 1.935, 1.999,
2.047, 2.002, 1.895, 2.018),
Variables = 1:16)
## Find the row with the absolute smallest RMSE
smallest <- pickSizeBest(example, metric = "RMSE", maximize = FALSE)
smallest
## Now one that is within 10% of the smallest
within10Pct <- pickSizeTolerance(example, metric = "RMSE", tol = 10, maximize = FALSE)
within10Pct
minRMSE <- min(example$RMSE)
example$Tolerance <- (example$RMSE - minRMSE)/minRMSE * 100
## Plot the profile and the subsets selected using the
## two different criteria
par(mfrow = c(2, 1), mar = c(3, 4, 1, 2))
plot(example$Variables[-c(smallest, within10Pct)],
example$RMSE[-c(smallest, within10Pct)],
ylim = extendrange(example$RMSE),
ylab = "RMSE", xlab = "Variables")
points(example$Variables[smallest],
example$RMSE[smallest], pch = 16, cex= 1.3)
points(example$Variables[within10Pct],
example$RMSE[within10Pct], pch = 17, cex= 1.3)
with(example, plot(Variables, Tolerance))
abline(h = 10, lty = 2, col = "darkgrey")
